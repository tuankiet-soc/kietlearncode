import gspread
import pandas as pd
from oauth2client.service_account import ServiceAccountCredentials
from google.cloud import bigquery
from datetime import datetime
import pytz

# -------------------------------
# 1. Config chung
# -------------------------------
scope = ["https://spreadsheets.google.com/feeds",
         "https://www.googleapis.com/auth/drive"]

CREDENTIALS_PATH = "c:/Users/kiet.trantuan/Desktop/soc-planning-2b70d5a26ace.json"
creds = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_PATH, scope)
client = gspread.authorize(creds)

PROJECT_ID = "soc-planning"
DATASET_ID = "spx25226"
bq_client = bigquery.Client.from_service_account_json(CREDENTIALS_PATH)

# Các cột cần ép kiểu
INT_COLS = ["vol", "cnt_to", "cnt_to_bulky"]
FLOAT_COLS = ["hc_request", "hc_commit","hc_converst","wh","wroking_hour_normal","wroking_hour_ot","hc_ot_kpi","hc_ot_normal","Lhpacked Ontime","Total LHpacked Inbound","%Ontime","Overdue","Late Order D-1","%Overdue","Volume","total_inbound","total_outbound","total_return","vol_arrive","Pending_Unload","Pending_Inbound_forward","Pending_Inbound_return","Pending_Packed","Pending_Seal","Pending_Linehaul","Pending_Return","Pending_3PL_Handover","Pending_3PL_Inbound","Pending_Cache_Order","Pending_Intercept","vol","vol_bulky"]  # có thể có số thập phân
DATETIME_COLS = [
    "depart_time", "seal_time", "loading_time",
    "arrive_time_at_outbound_station", "arrive_time_at_inbound_station",
    "unseal_time", "unloaded_time", "arrive_time", "date","date_ops","sla_date","cdate","c_date","arrived_date","Snapshot_Time","sla_lhpacked"
]

# -------------------------------
# 2. Danh sách sheet → table
# -------------------------------
TABLE_CONFIGS = [
    {
        "sheet_name": "Trip Inbound",
        "worksheet": "Sheet1",
        "table_id": "trip_inbound",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:X"
    },
    {
        "sheet_name": "Trip Outbound",
        "worksheet": "Depart",
        "table_id": "trip_outbound",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:T"
    },
    {
        "sheet_name": "raw_olm",
        "worksheet": "Convert Booking",
        "table_id": "booking_os",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:K"
    },
    {
        "sheet_name": "raw_olm",
        "worksheet": "Convert commit",
        "table_id": "commit_os",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:M"
    },
    {
        "sheet_name": "HCM SOC_Verify OT",
        "worksheet": "raw+cook",
        "table_id": "actual_working_hour",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:H"
    },
    {
        "sheet_name": "Storage data",
        "worksheet": "raw_ontime",
        "table_id": "raw_ontime",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:E"
    },
    {
        "sheet_name": "Storage data",
        "worksheet": "raw_overdue",
        "table_id": "raw_overdue",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:E"
    },
    {
        "sheet_name": "Storage data",
        "worksheet": "raw_forecast",
        "table_id": "raw_forecast",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:H"
    },
    {
        "sheet_name": "Storage data",
        "worksheet": "raw_throughput",
        "table_id": "raw_throughput",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:E"
    },
    {
        "sheet_name": "Storage data",
        "worksheet": "raw_forecast",
        "table_id": "raw_forecast",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:H"
    },
    {
        "sheet_name": "Storage data",
        "worksheet": "raw_arrived",
        "table_id": "raw_arrived",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:D"
    },
    {
        "sheet_name": "Storage data",
        "worksheet": "raw_backlog",
        "table_id": "raw_backlog",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:O"
    },
    {
        "sheet_name": "Storage data",
        "worksheet": "raw_ontime_before",
        "table_id": "raw_ontime_before",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:E"
    },
    {
        "sheet_name": "Storage data",
        "worksheet": "raw_bulky",
        "table_id": "raw_bulky",
        "write_mode": "WRITE_TRUNCATE",
        "range_cols": "A1:C"
    }
]

# -------------------------------
# 3. Hàm xử lý 1 sheet → 1 table
# -------------------------------
def load_sheet_to_bq(sheet_name, worksheet_name, table_id,
                     write_mode="WRITE_TRUNCATE", range_cols="A1:T"):
    sheet = client.open(sheet_name).worksheet(worksheet_name)
    last_row = len(sheet.get_all_values())

    # Giới hạn cột theo config
    data = sheet.get(f"{range_cols}{last_row}")
    df = pd.DataFrame(data[1:], columns=data[0])

    # Làm sạch dữ liệu
    df = df.replace(r'^\s*$', pd.NA, regex=True).dropna(how="all")

    # Ép kiểu INT
    for col in INT_COLS:
        if col in df.columns:
            df[col] = df[col].astype(str).str.replace(",", "", regex=False)
            df[col] = pd.to_numeric(df[col], errors="coerce").astype("Int64")

    # Ép kiểu FLOAT
    for col in FLOAT_COLS:
        if col in df.columns:
            df[col] = df[col].astype(str).str.replace(",", "", regex=False)
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # Ép kiểu DATETIME → local VN
    for col in DATETIME_COLS:
        if col in df.columns:
            try:
                tmp = pd.to_datetime(df[col], errors="coerce")
                df[col] = tmp.dt.tz_localize("UTC").dt.tz_convert("Asia/Ho_Chi_Minh").dt.tz_localize(None)
            except Exception as e:
                print(f"⚠️ Lỗi parse datetime cột {col}: {e}")

    # Thêm query_time (local VN)
    vn_now = datetime.now(pytz.timezone("Asia/Ho_Chi_Minh"))
    df["query_time"] = vn_now.replace(tzinfo=None)

    # Schema BigQuery
    schema = []
    for col in df.columns:
        if col in INT_COLS:
            schema.append(bigquery.SchemaField(col, "INT64"))
        elif col in FLOAT_COLS:
            schema.append(bigquery.SchemaField(col, "FLOAT64"))
        elif col in DATETIME_COLS or col == "query_time":
            schema.append(bigquery.SchemaField(col, "DATETIME"))
        else:
            schema.append(bigquery.SchemaField(col, "STRING"))

    # Load lên BigQuery
    table_full_id = f"{PROJECT_ID}.{DATASET_ID}.{table_id}"
    job_config = bigquery.LoadJobConfig(
        write_disposition=write_mode,
        schema=schema,
        autodetect=False
    )
    job = bq_client.load_table_from_dataframe(df, table_full_id, job_config=job_config)
    job.result()

    print(f"✅ {sheet_name}/{worksheet_name} → {table_full_id}: "
          f"{df.shape[0]} rows (cols={range_cols}, mode={write_mode}, datetime=VN local)")

# -------------------------------
# 4. Chạy nhiều sheet → nhiều table
# -------------------------------
for cfg in TABLE_CONFIGS:
    load_sheet_to_bq(
        cfg["sheet_name"],
        cfg["worksheet"],
        cfg["table_id"],
        cfg["write_mode"],
        cfg["range_cols"]
    )
